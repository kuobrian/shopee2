{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyahocorasick\n",
      "  Downloading pyahocorasick-1.4.1.tar.gz (321 kB)\n",
      "Building wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py): started\n",
      "  Building wheel for pyahocorasick (setup.py): finished with status 'done'\n",
      "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.1-cp36-cp36m-win_amd64.whl size=38083 sha256=973be02debeddad60a11313273f2cd18d905d983a86945159573813715f5d06e\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\a5\\cf\\c2\\c79ce865644045e393f55296c0a2e7127dc06d620bc139c15c\n",
      "Successfully built pyahocorasick\n",
      "Installing collected packages: pyahocorasick\n",
      "Successfully installed pyahocorasick-1.4.1\n",
      "Collecting spacy==3.0.*\n",
      "  Downloading spacy-3.0.5-cp36-cp36m-win_amd64.whl (11.6 MB)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy==3.0.*) (3.7.4.3)\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.5-cp36-cp36m-win_amd64.whl (35 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.4-cp36-cp36m-win_amd64.whl (6.5 MB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy==3.0.*) (1.19.4)\n",
      "Collecting srsly<3.0.0,>=2.4.0\n",
      "  Downloading srsly-2.4.0-cp36-cp36m-win_amd64.whl (449 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy==3.0.*) (2.24.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy==3.0.*) (20.4)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.0\n",
      "  Downloading spacy_legacy-3.0.1-py2.py3-none-any.whl (7.0 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.1\n",
      "  Downloading catalogue-2.0.1-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy==3.0.*) (4.46.0)\n",
      "Collecting pydantic<1.8.0,>=1.7.1\n",
      "  Downloading pydantic-1.7.3-cp36-cp36m-win_amd64.whl (1.7 MB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.5-cp36-cp36m-win_amd64.whl (20 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy==3.0.*) (2.11.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy==3.0.*) (50.1.0)\n",
      "Collecting thinc<8.1.0,>=8.0.2\n",
      "  Downloading thinc-8.0.2-cp36-cp36m-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy==3.0.*) (1.7.0)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.4.0-py3-none-any.whl (36 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.5-cp36-cp36m-win_amd64.whl (109 kB)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy==3.0.*) (7.1.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python36\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.*) (2.6)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.*) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python36\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.*) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.*) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages (from packaging>=20.0->spacy==3.0.*) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages (from packaging>=20.0->spacy==3.0.*) (1.15.0)\n",
      "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages (from pydantic<1.8.0,>=1.7.1->spacy==3.0.*) (0.8)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages (from jinja2->spacy==3.0.*) (1.1.1)\n",
      "Collecting contextvars<3,>=2.4; python_version < \"3.7\"\n",
      "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy==3.0.*) (3.1.0)\n",
      "Collecting smart-open<4.0.0,>=2.2.0\n",
      "  Downloading smart_open-3.0.0.tar.gz (113 kB)\n",
      "Collecting immutables>=0.9\n",
      "  Downloading immutables-0.15-cp36-cp36m-win_amd64.whl (56 kB)\n",
      "Building wheels for collected packages: contextvars, smart-open\n",
      "  Building wheel for contextvars (setup.py): started\n",
      "  Building wheel for contextvars (setup.py): finished with status 'done'\n",
      "  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7669 sha256=e55849a37f89d0a6e1bc11fa8a793088dbd61fa8a3e216b880c004d9b97197c9\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\41\\11\\53\\911724983aa48deb94792432e14e518447212dd6c5477d49d3\n",
      "  Building wheel for smart-open (setup.py): started\n",
      "  Building wheel for smart-open (setup.py): finished with status 'done'\n",
      "  Created wheel for smart-open: filename=smart_open-3.0.0-py3-none-any.whl size=107101 sha256=1a5922e294a553cbd906e7029a56247dbb6734369090a177886c70557b1eabc7\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\88\\2a\\d4\\f2e9023989d4d4b3574f268657cb6cd23994665a038803f547\n",
      "Successfully built contextvars smart-open\n",
      "Installing collected packages: typer, cymem, blis, catalogue, srsly, wasabi, spacy-legacy, pydantic, murmurhash, immutables, contextvars, preshed, thinc, smart-open, pathy, spacy\n",
      "Successfully installed blis-0.7.4 catalogue-2.0.1 contextvars-2.4 cymem-2.0.5 immutables-0.15 murmurhash-1.0.5 pathy-0.4.0 preshed-3.0.5 pydantic-1.7.3 smart-open-3.0.0 spacy-3.0.5 spacy-legacy-3.0.1 srsly-2.4.0 thinc-8.0.2 typer-0.3.2 wasabi-0.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyahocorasick\n",
    "!pip install spacy==3.0.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# from pandarallel import pandarallel\n",
    "# pandarallel.initialize()\n",
    "\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "import random\n",
    "\n",
    "import ahocorasick\n",
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Address Elements Extraction Dataset/train.csv\")\n",
    "df.set_index(\"id\", inplace=True)\n",
    "df['POI'] = np.nan\n",
    "df['street'] = np.nan\n",
    "\n",
    "def extract_entities(row):\n",
    "    extracted = row['POI/street'].split(\"/\")\n",
    "    \n",
    "    if len(extracted) == 2:\n",
    "        poi, street = extracted\n",
    "        if poi.strip() != '':\n",
    "            row['POI'] = poi\n",
    "        \n",
    "        if street.strip() != '':\n",
    "            row['street'] = street\n",
    "        \n",
    "    return row\n",
    "\n",
    "df = df.apply(extract_entities, axis=1)\n",
    "nlp = spacy.blank('id')  # create blank Language class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_address</th>\n",
       "      <th>POI/street</th>\n",
       "      <th>POI</th>\n",
       "      <th>street</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jl kapuk timur delta sili iii lippo cika 11 a cicau cikarang pusat</td>\n",
       "      <td>/jl kapuk timur delta sili iii lippo cika</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jl kapuk timur delta sili iii lippo cika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aye, jati sampurna</td>\n",
       "      <td>/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setu siung 119 rt 5 1 13880 cipayung</td>\n",
       "      <td>/siung</td>\n",
       "      <td>NaN</td>\n",
       "      <td>siung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toko dita, kertosono</td>\n",
       "      <td>toko dita/</td>\n",
       "      <td>toko dita</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jl. orde baru</td>\n",
       "      <td>/jl. orde baru</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jl. orde baru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           raw_address  \\\n",
       "id                                                                       \n",
       "0   jl kapuk timur delta sili iii lippo cika 11 a cicau cikarang pusat   \n",
       "1                                                   aye, jati sampurna   \n",
       "2                                 setu siung 119 rt 5 1 13880 cipayung   \n",
       "3                                                 toko dita, kertosono   \n",
       "4                                                        jl. orde baru   \n",
       "\n",
       "                                   POI/street        POI  \\\n",
       "id                                                         \n",
       "0   /jl kapuk timur delta sili iii lippo cika        NaN   \n",
       "1                                           /        NaN   \n",
       "2                                      /siung        NaN   \n",
       "3                                  toko dita/  toko dita   \n",
       "4                              /jl. orde baru        NaN   \n",
       "\n",
       "                                      street  \n",
       "id                                            \n",
       "0   jl kapuk timur delta sili iii lippo cika  \n",
       "1                                        NaN  \n",
       "2                                      siung  \n",
       "3                                        NaN  \n",
       "4                              jl. orde baru  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def _build_aho(words):\n",
    "    aho = ahocorasick.Automaton()\n",
    "    for idx, key in enumerate(words):\n",
    "        \n",
    "        aho.add_word(key, (idx, key))\n",
    "\n",
    "    return aho\n",
    "\n",
    "def format_data(text, poi, street):\n",
    "    entities = []\n",
    "    _text = deepcopy(text)\n",
    "    \n",
    "    if isinstance(poi, str):\n",
    "        aho = _build_aho([poi])\n",
    "        aho.make_automaton()\n",
    "        latest_char_idx = 0\n",
    "        \n",
    "        for end, (_, word) in aho.iter(_text):\n",
    "            start = end - len(word) + 1\n",
    "            \n",
    "            if start < latest_char_idx:\n",
    "                continue\n",
    "\n",
    "            entities.append((start, end + 1, 'POI'))\n",
    "            _text = _text.replace(word, \" \" * len(word))\n",
    "            latest_char_idx = end + 1\n",
    "    if isinstance(street, str):\n",
    "        aho = _build_aho([street])\n",
    "        aho.make_automaton()\n",
    "        latest_char_idx = 0\n",
    "\n",
    "        for end, (_, word) in aho.iter(_text):\n",
    "            start = end - len(word) + 1\n",
    "            if start < latest_char_idx:\n",
    "                continue\n",
    "\n",
    "            entities.append((start, end + 1, 'STREET'))\n",
    "            latest_char_idx = end + 1\n",
    "    te = nlp.make_doc(text)\n",
    "    return Example.from_dict(nlp.make_doc(text), {\"entities\": entities}), \n",
    "\n",
    "# row = df.loc[5]\n",
    "# example = format_data(row['raw_address'], row['POI'], row['street'])\n",
    "# print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Spacy examples...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing Spacy examples...\")\n",
    "\n",
    "examples = []\n",
    "for idx in df.index:\n",
    "    try:\n",
    "        row = df.loc[idx]\n",
    "        example = format_data(row['raw_address'], row['POI'], row['street'])\n",
    "        examples.append(example)\n",
    "    except Exception as e:\n",
    "        print(idx)\n",
    "        print(\"-\" * 50)\n",
    "        print(e)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    }
   ],
   "source": [
    "print(len(examples))\n",
    "df_test = pd.read_csv(\"./Address Elements Extraction Dataset/test.csv\")\n",
    "df_test.set_index(\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTemp(i, test_df, ner_nlp):\n",
    "    print(\"==================   saveTemp\")\n",
    "    submission = []\n",
    "    for idx, row in test_df.iloc[:].iterrows():\n",
    "        doc = ner_nlp(row['raw_address'])\n",
    "        tmp = {'id': idx}\n",
    "        for ent in doc.ents:\n",
    "            tmp[ent.label_] = ent.text\n",
    "        submission.append(tmp)\n",
    "    submission = pd.DataFrame(submission)\n",
    "    submission = submission.fillna(\"\")\n",
    "    combine_lambda = lambda x: '{}/{}'.format(x['POI'], x['STREET'])\n",
    "    submission[\"POI/street\"] = submission.apply(combine_lambda, axis = 1)\n",
    "    \n",
    "    pd.DataFrame({'id':submission['id'],\n",
    "                  'POI/street':submission['POI/street']}).to_csv('./submission_all_{}.csv'.format(i), header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    }
   ],
   "source": [
    "def train_spacy(nlp, examples, iterations):\n",
    "    TRAIN_DATA = examples\n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.add_pipe('ner', last=True)\n",
    "    min_losses = np.inf\n",
    "    \n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        \n",
    "        for itn in range(iterations):\n",
    "            print(\"Starting iteration \" + str(itn))\n",
    "            \n",
    "            random.shuffle(examples)\n",
    "            losses = {}\n",
    "#             for example in examples:\n",
    "#                 nlp.update(\n",
    "#                     [example],\n",
    "#                     drop=0.2,  # dropout - make it harder to memorise data\n",
    "#                     sgd=optimizer,  # callable to update weights\n",
    "#                     losses=losses)\n",
    "\n",
    "            for batch in spacy.util.minibatch(examples, size=5):\n",
    "                nlp.update(batch,\n",
    "                            drop = 0.2,  # dropout - make it harder to memorise data\n",
    "                            sgd = optimizer,  # callable to update weights\n",
    "                            losses = losses)\n",
    "            print(losses,itn%20 == 0)\n",
    "            if losses['ner'] < min_losses:\n",
    "                min_losses = losses['ner']\n",
    "                if itn%20 == 0 and itn != 0 :\n",
    "                    nlp.to_disk(\"./street_pipeline\")\n",
    "                    saveTemp(itn, df_test, nlp)\n",
    "                \n",
    "    return nlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    }
   ],
   "source": [
    "spacy.require_gpu()\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0\n",
      "{'ner': 6250.291559555151} True\n",
      "Starting iteration 1\n",
      "{'ner': 4514.416197725128} False\n",
      "Starting iteration 2\n",
      "{'ner': 3728.4837143832306} False\n",
      "Starting iteration 3\n",
      "{'ner': 3141.779219829178} False\n",
      "Starting iteration 4\n",
      "{'ner': 2617.1965455801746} False\n",
      "Starting iteration 5\n",
      "{'ner': 2359.660586907646} False\n",
      "Starting iteration 6\n",
      "{'ner': 2054.9478107195196} False\n",
      "Starting iteration 7\n",
      "{'ner': 1866.8040904196143} False\n",
      "Starting iteration 8\n",
      "{'ner': 1579.3953989492352} False\n",
      "Starting iteration 9\n",
      "{'ner': 1487.9122692405915} False\n",
      "Starting iteration 10\n",
      "{'ner': 1390.5660515148347} False\n",
      "Starting iteration 11\n",
      "{'ner': 1257.9426918019456} False\n",
      "Starting iteration 12\n",
      "{'ner': 1175.8923320120423} False\n",
      "Starting iteration 13\n",
      "{'ner': 1145.9400623274498} False\n",
      "Starting iteration 14\n",
      "{'ner': 1078.4527189640362} False\n",
      "Starting iteration 15\n",
      "{'ner': 942.2840581953725} False\n",
      "Starting iteration 16\n",
      "{'ner': 939.6170621359341} False\n",
      "Starting iteration 17\n",
      "{'ner': 845.7042424177283} False\n",
      "Starting iteration 18\n",
      "{'ner': 846.8177745577545} False\n",
      "Starting iteration 19\n",
      "{'ner': 840.7029543593451} False\n",
      "Starting iteration 20\n",
      "{'ner': 781.0567302062329} True\n",
      "==================   saveTemp\n",
      "Starting iteration 21\n",
      "{'ner': 729.8960646015075} False\n",
      "Starting iteration 22\n",
      "{'ner': 750.585491425788} False\n",
      "Starting iteration 23\n",
      "{'ner': 665.6144733334473} False\n",
      "Starting iteration 24\n",
      "{'ner': 660.0206864079549} False\n"
     ]
    }
   ],
   "source": [
    "ner_nlp = train_spacy(nlp, examples[:5000], 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0\n",
      "{'ner': 11311.390522945101} True\n",
      "Starting iteration 1\n",
      "{'ner': 7955.781866206249} False\n",
      "Starting iteration 2\n",
      "{'ner': 6568.394899257277} False\n",
      "Starting iteration 3\n",
      "{'ner': 5815.826171497893} False\n",
      "Starting iteration 4\n",
      "{'ner': 5065.116900858079} False\n",
      "Starting iteration 5\n",
      "{'ner': 4641.345061616835} False\n",
      "Starting iteration 6\n",
      "{'ner': 4130.603815155804} False\n",
      "Starting iteration 7\n",
      "{'ner': 3740.7190968296577} False\n",
      "Starting iteration 8\n",
      "{'ner': 3515.7429153719613} False\n",
      "Starting iteration 9\n",
      "{'ner': 3128.314397619845} False\n",
      "Starting iteration 10\n",
      "{'ner': 3074.436420949807} False\n",
      "Starting iteration 11\n",
      "{'ner': 2787.7388601123766} False\n",
      "Starting iteration 12\n",
      "{'ner': 2718.793744782713} False\n",
      "Starting iteration 13\n",
      "{'ner': 2516.7036806742685} False\n",
      "Starting iteration 14\n",
      "{'ner': 2402.640504459179} False\n",
      "Starting iteration 15\n",
      "{'ner': 2213.78560536515} False\n",
      "Starting iteration 16\n",
      "{'ner': 2186.213508641598} False\n",
      "Starting iteration 17\n",
      "{'ner': 2089.1769942182777} False\n",
      "Starting iteration 18\n",
      "{'ner': 1949.8624622952138} False\n",
      "Starting iteration 19\n",
      "{'ner': 1880.459198285592} False\n",
      "Starting iteration 20\n",
      "{'ner': 1843.807024271169} True\n",
      "==================   saveTemp\n",
      "Starting iteration 21\n",
      "{'ner': 1733.8819177871142} False\n",
      "Starting iteration 22\n",
      "{'ner': 1720.2270136320683} False\n",
      "Starting iteration 23\n",
      "{'ner': 1669.4676630979584} False\n",
      "Starting iteration 24\n",
      "{'ner': 1571.5006955758154} False\n"
     ]
    }
   ],
   "source": [
    "ner_nlp = train_spacy(ner_nlp, examples[:10000], 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "address: orahili badalu fukagambo 22862\n",
      "expected poi: nan\n",
      "expected street: fukagambo\n",
      "\n",
      "orahili badalu - POI\n",
      "--------------------------------------------------\n",
      "address: mand, raya gilim gilimanuk\n",
      "expected poi: mandapin\n",
      "expected street: raya gilim\n",
      "\n",
      "raya gilim - STREET\n",
      "--------------------------------------------------\n",
      "address: raya indu, no 62 indo kimia, cikarang selatan\n",
      "expected poi: indojaya kimia\n",
      "expected street: raya indu\n",
      "\n",
      "raya indu - STREET\n",
      "--------------------------------------------------\n",
      "address: pegad jend besar ah nasu,\n",
      "expected poi: nan\n",
      "expected street: nan\n",
      "\n",
      "pegad - POI\n",
      "jend besar ah nasu - STREET\n",
      "--------------------------------------------------\n",
      "address: kar jawa pelai pelaihari\n",
      "expected poi: nan\n",
      "expected street: kar jawa pelai\n",
      "\n",
      "kar jawa pelai - STREET\n",
      "--------------------------------------------------\n",
      "address: tb. mekar maju, surya kenc selabatu cikole\n",
      "expected poi: tb. mekar maju\n",
      "expected street: surya kenc\n",
      "\n",
      "surya kenc - STREET\n",
      "--------------------------------------------------\n",
      "address: cemp 10 nagasari karawang barat\n",
      "expected poi: nan\n",
      "expected street: cemp\n",
      "\n",
      "cemp 10 - STREET\n",
      "--------------------------------------------------\n",
      "address: margadadi anggasara 5 indramayu\n",
      "expected poi: nan\n",
      "expected street: anggasara\n",
      "\n",
      "anggasara - STREET\n",
      "--------------------------------------------------\n",
      "address: bendo mungal gg. 2 350 67153 bangil\n",
      "expected poi: nan\n",
      "expected street: gg. 2\n",
      "\n",
      "bendo mungal - POI\n",
      "gg. 2 - STREET\n",
      "--------------------------------------------------\n",
      "address: jl. tole iska, 9 depok ruko bukit novo pancoran mas\n",
      "expected poi: ruko bukit novo\n",
      "expected street: jl. tole iska\n",
      "\n",
      "jl. tole iska - STREET\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df.iloc[28000:28010].iterrows():\n",
    "    print(f\"address: {row['raw_address']}\")\n",
    "    print(f\"expected poi: {row['POI']}\")\n",
    "    print(f\"expected street: {row['street']}\")\n",
    "    print()\n",
    "    \n",
    "    doc = ner_nlp(row['raw_address'])\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, \"-\", ent.label_)\n",
    "\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>STREET</th>\n",
       "      <th>POI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>s. par</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>angg per</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mand imog</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>raya nga sri</td>\n",
       "      <td>ud agung rej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cut mutia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>49995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>toko mbak farid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>49996</td>\n",
       "      <td>vete 3 cari</td>\n",
       "      <td>tk. ridho kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>49997</td>\n",
       "      <td>nasio</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>49998</td>\n",
       "      <td>jl. mujair raya</td>\n",
       "      <td>graha indah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>49999</td>\n",
       "      <td>adi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           STREET              POI\n",
       "0          0           s. par              NaN\n",
       "1          1         angg per              NaN\n",
       "2          2        mand imog              NaN\n",
       "3          3     raya nga sri     ud agung rej\n",
       "4          4        cut mutia              NaN\n",
       "...      ...              ...              ...\n",
       "49995  49995              NaN  toko mbak farid\n",
       "49996  49996      vete 3 cari   tk. ridho kids\n",
       "49997  49997            nasio              NaN\n",
       "49998  49998  jl. mujair raya      graha indah\n",
       "49999  49999              adi              NaN\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = []\n",
    "for idx, row in df_test.iloc[:].iterrows():\n",
    "    doc = ner_nlp(row['raw_address'])\n",
    "    tmp = {'id': idx}\n",
    "    for ent in doc.ents:\n",
    "        tmp[ent.label_] = ent.text\n",
    "    submission.append(tmp)\n",
    "pd.DataFrame(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(submission)\n",
    "# submission['POI/street'] = submission['POI'] + '/' + submission['STREET']\n",
    "submission = submission.fillna(\"\")\n",
    "combine_lambda = lambda x: '{}/{}'.format(x['POI'], x['STREET'])\n",
    "submission[\"POI/street\"] = submission.apply(combine_lambda, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>STREET</th>\n",
       "      <th>POI</th>\n",
       "      <th>POI/street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>s. par</td>\n",
       "      <td></td>\n",
       "      <td>/s. par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>angg per</td>\n",
       "      <td></td>\n",
       "      <td>/angg per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mand imog</td>\n",
       "      <td></td>\n",
       "      <td>/mand imog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>raya nga sri</td>\n",
       "      <td>ud agung rej</td>\n",
       "      <td>ud agung rej/raya nga sri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cut mutia</td>\n",
       "      <td></td>\n",
       "      <td>/cut mutia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        STREET           POI                 POI/street\n",
       "0   0        s. par                                  /s. par\n",
       "1   1      angg per                                /angg per\n",
       "2   2     mand imog                               /mand imog\n",
       "3   3  raya nga sri  ud agung rej  ud agung rej/raya nga sri\n",
       "4   4     cut mutia                               /cut mutia"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'id':submission['id'],\n",
    "              'POI/street':submission['POI/street']}).to_csv('./submission_test.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
